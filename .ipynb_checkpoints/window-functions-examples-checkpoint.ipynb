{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark SQL supports three kinds of window functions ranking functions, analytic functions, and aggregate functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the available ranking and analytic functions\n",
    "\n",
    "Ranking functions : rank,denseRank ,percentRank,ntile, rowNumber\n",
    "\n",
    "\n",
    "Analytic functions : cumeDist,firstValue,lastValue,lag,lead.\n",
    "\n",
    "\n",
    "Aggregate functions, users can use any existing aggregate function as a window function like sum,mean,max,min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"window-function\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"./source/stock_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', '_c1', '_c2', '_c3', '_c4', '_c5', '_c6']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+-----+-----+-----+------+\n",
      "|    Date|Ticker| Open| High|  Low|Close|Volume|\n",
      "+--------+------+-----+-----+-----+-----+------+\n",
      "|20100721|     A|27.68| 28.2|27.41|27.58| 44528|\n",
      "|20100722|     A|27.95|28.87|27.95|28.72| 36494|\n",
      "|20100723|     A|28.56|29.41|28.45| 29.3| 37153|\n",
      "|20100726|     A|29.22|29.67|29.11|29.64| 21256|\n",
      "|20100727|     A|29.73|29.73|28.81|28.87| 33410|\n",
      "|20100728|     A|28.79|29.27|28.74|28.78| 31156|\n",
      "|20100729|     A|28.97|29.15|27.78|28.15| 44085|\n",
      "|20100730|     A|27.78|28.17|27.66|27.93| 36943|\n",
      "|20100802|     A|28.35|28.97| 28.2|28.82| 28989|\n",
      "|20100803|     A| 28.7|28.73| 27.8|27.84| 42401|\n",
      "|20100804|     A|27.86|28.35|27.75|28.29| 23525|\n",
      "|20100805|     A|28.03|28.63|27.96|28.46| 20682|\n",
      "|20100806|     A|28.18|28.75|28.07|28.73| 33777|\n",
      "|20100809|     A|28.92|29.87|28.87|29.82| 36889|\n",
      "|20100810|     A|29.44|29.68|29.13|29.46| 34866|\n",
      "|20100811|     A|28.86| 28.9|27.98|28.22| 28271|\n",
      "|20100812|     A|27.65|27.78|27.41|27.53| 32566|\n",
      "|20100813|     A|27.39|27.85| 27.3|27.35| 24469|\n",
      "|20100816|     A|27.11|27.68|   27|27.16| 33231|\n",
      "|20100817|     A|28.87|29.53|28.42|29.28| 73050|\n",
      "+--------+------+-----+-----+-----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 =df.select(df['_c0'].alias(\"Date\"),\n",
    "          df['_c1'].alias(\"Ticker\"),\n",
    "          df['_c2'].alias(\"Open\"),\n",
    "          df['_c3'].alias(\"High\"),\n",
    "          df['_c4'].alias(\"Low\"),\n",
    "          df['_c5'].alias(\"Close\"),\n",
    "          df['_c6'].alias(\"Volume\"),\n",
    "         )\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Ticker', 'Open', 'high', 'low', 'Close', 'volume']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one more way to renanming the columns in dataframe \n",
    "df1 = df.toDF('Date','Ticker','Open','high','low','Close','volume')\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data to temp table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.registerTempTable(\"stock_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+-----+-----+-----+------+\n",
      "|    Date|Ticker| Open| high|  low|Close|volume|\n",
      "+--------+------+-----+-----+-----+-----+------+\n",
      "|20100721|     A|27.68| 28.2|27.41|27.58| 44528|\n",
      "|20100722|     A|27.95|28.87|27.95|28.72| 36494|\n",
      "|20100723|     A|28.56|29.41|28.45| 29.3| 37153|\n",
      "|20100726|     A|29.22|29.67|29.11|29.64| 21256|\n",
      "|20100727|     A|29.73|29.73|28.81|28.87| 33410|\n",
      "|20100728|     A|28.79|29.27|28.74|28.78| 31156|\n",
      "|20100729|     A|28.97|29.15|27.78|28.15| 44085|\n",
      "|20100730|     A|27.78|28.17|27.66|27.93| 36943|\n",
      "|20100802|     A|28.35|28.97| 28.2|28.82| 28989|\n",
      "|20100803|     A| 28.7|28.73| 27.8|27.84| 42401|\n",
      "|20100804|     A|27.86|28.35|27.75|28.29| 23525|\n",
      "|20100805|     A|28.03|28.63|27.96|28.46| 20682|\n",
      "|20100806|     A|28.18|28.75|28.07|28.73| 33777|\n",
      "|20100809|     A|28.92|29.87|28.87|29.82| 36889|\n",
      "|20100810|     A|29.44|29.68|29.13|29.46| 34866|\n",
      "|20100811|     A|28.86| 28.9|27.98|28.22| 28271|\n",
      "|20100812|     A|27.65|27.78|27.41|27.53| 32566|\n",
      "|20100813|     A|27.39|27.85| 27.3|27.35| 24469|\n",
      "|20100816|     A|27.11|27.68|   27|27.16| 33231|\n",
      "|20100817|     A|28.87|29.53|28.42|29.28| 73050|\n",
      "+--------+------+-----+-----+-----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from stock_data\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   10937|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from stock_data\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Fuction \n",
    "### Lag and Lead functions :\n",
    "\n",
    "The LAG function is an analytic function that lets you query more than one row in a table at a time without having to join the table to itself. It returns values from a previous row in the table.\n",
    "\n",
    "the LEAD function is an analytic function that lets you query more than one row in a table at a time without having to join the table to itself. It returns values from the next row in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+---------------+\n",
      "|Ticker|    Date|Close|yesterday_price|\n",
      "+------+--------+-----+---------------+\n",
      "|   GIS|20100721|35.03|           null|\n",
      "|   GIS|20100722|35.36|          35.03|\n",
      "|   GIS|20100723|35.52|          35.36|\n",
      "|   GIS|20100726|35.44|          35.52|\n",
      "|   GIS|20100727|35.89|          35.44|\n",
      "|   GIS|20100728|35.44|          35.89|\n",
      "|   GIS|20100729|34.13|          35.44|\n",
      "|   GIS|20100730| 34.2|          34.13|\n",
      "|   GIS|20100802|34.35|           34.2|\n",
      "|   GIS|20100803|33.98|          34.35|\n",
      "|   GIS|20100804|34.62|          33.98|\n",
      "|   GIS|20100805|33.85|          34.62|\n",
      "|   GIS|20100806|33.57|          33.85|\n",
      "|   GIS|20100809| 33.7|          33.57|\n",
      "|   GIS|20100810|33.98|           33.7|\n",
      "|   GIS|20100811|33.81|          33.98|\n",
      "|   GIS|20100812|34.43|          33.81|\n",
      "|   GIS|20100813|34.86|          34.43|\n",
      "|   GIS|20100816|35.15|          34.86|\n",
      "|   GIS|20100817|35.38|          35.15|\n",
      "+------+--------+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yesterday_close_price = spark.sql(\"select Ticker,Date,Close ,\\\n",
    "                    lag(Close,1) over (partition by  Ticker order by Date ) as yesterday_price from stock_data \")\n",
    "\n",
    "yesterday_close_price.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+--------------+\n",
      "|Ticker|    Date|Close|next_day_price|\n",
      "+------+--------+-----+--------------+\n",
      "|   GIS|20100721|35.03|         35.36|\n",
      "|   GIS|20100722|35.36|         35.52|\n",
      "|   GIS|20100723|35.52|         35.44|\n",
      "|   GIS|20100726|35.44|         35.89|\n",
      "|   GIS|20100727|35.89|         35.44|\n",
      "|   GIS|20100728|35.44|         34.13|\n",
      "|   GIS|20100729|34.13|          34.2|\n",
      "|   GIS|20100730| 34.2|         34.35|\n",
      "|   GIS|20100802|34.35|         33.98|\n",
      "|   GIS|20100803|33.98|         34.62|\n",
      "|   GIS|20100804|34.62|         33.85|\n",
      "|   GIS|20100805|33.85|         33.57|\n",
      "|   GIS|20100806|33.57|          33.7|\n",
      "|   GIS|20100809| 33.7|         33.98|\n",
      "|   GIS|20100810|33.98|         33.81|\n",
      "|   GIS|20100811|33.81|         34.43|\n",
      "|   GIS|20100812|34.43|         34.86|\n",
      "|   GIS|20100813|34.86|         35.15|\n",
      "|   GIS|20100816|35.15|         35.38|\n",
      "|   GIS|20100817|35.38|         35.13|\n",
      "|   GIS|20100819|35.13|         35.14|\n",
      "|   GIS|20100820|35.14|          null|\n",
      "|     K|20100721|51.14|          50.6|\n",
      "|     K|20100722| 50.6|          51.1|\n",
      "|     K|20100723| 51.1|         51.34|\n",
      "|     K|20100726|51.34|         52.48|\n",
      "|     K|20100727|52.48|         51.52|\n",
      "|     K|20100728|51.52|         47.98|\n",
      "|     K|20100729|47.98|         50.05|\n",
      "|     K|20100730|50.05|            50|\n",
      "+------+--------+-----+--------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "next_day_close = spark.sql(\"select Ticker,Date,Close ,\\\n",
    "                        lead(Close,1) over (partition by  Ticker order by Date ) as next_day_price from stock_data \")\n",
    "\n",
    "next_day_close.show(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First_value and Last_value : \n",
    "\n",
    "FIRST_VALUE returns the first value in an ordered set of values.\n",
    "\n",
    "LAST_VALUE returns the last value in an ordered set of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+-----------+\n",
      "|Ticker|    Date|   High|first_value|\n",
      "+------+--------+-------+-----------+\n",
      "|   GIS|20100721|  35.56|      35.56|\n",
      "|   GIS|20100722|  35.48|      35.56|\n",
      "|   GIS|20100723|  35.58|      35.56|\n",
      "|   GIS|20100726|35.6852|      35.56|\n",
      "|   GIS|20100727|     36|      35.56|\n",
      "|   GIS|20100728|  35.91|      35.56|\n",
      "|   GIS|20100729|  35.11|      35.56|\n",
      "|   GIS|20100730|  34.48|      35.56|\n",
      "|   GIS|20100802|  35.03|      35.56|\n",
      "|   GIS|20100803|  34.42|      35.56|\n",
      "|   GIS|20100804|   34.7|      35.56|\n",
      "|   GIS|20100805|  34.52|      35.56|\n",
      "|   GIS|20100806|  33.73|      35.56|\n",
      "|   GIS|20100809|  33.87|      35.56|\n",
      "|   GIS|20100810|  34.15|      35.56|\n",
      "|   GIS|20100811|  33.98|      35.56|\n",
      "|   GIS|20100812|  34.44|      35.56|\n",
      "|   GIS|20100813|  35.17|      35.56|\n",
      "|   GIS|20100816|  35.16|      35.56|\n",
      "|   GIS|20100817|  35.54|      35.56|\n",
      "|   GIS|20100819|  35.29|      35.56|\n",
      "|   GIS|20100820|   35.2|      35.56|\n",
      "|     K|20100721|  51.84|      51.84|\n",
      "|     K|20100722| 51.625|      51.84|\n",
      "|     K|20100723|   51.4|      51.84|\n",
      "|     K|20100726|  51.51|      51.84|\n",
      "|     K|20100727|  52.58|      51.84|\n",
      "|     K|20100728|  52.48|      51.84|\n",
      "|     K|20100729|   50.1|      51.84|\n",
      "|     K|20100730|  50.16|      51.84|\n",
      "|     K|20100802|  50.53|      51.84|\n",
      "|     K|20100803|  50.07|      51.84|\n",
      "|     K|20100804|  50.95|      51.84|\n",
      "|     K|20100805|   50.6|      51.84|\n",
      "|     K|20100806|  50.24|      51.84|\n",
      "|     K|20100809|  51.09|      51.84|\n",
      "|     K|20100810|  51.84|      51.84|\n",
      "|     K|20100811|  51.38|      51.84|\n",
      "|     K|20100812|  50.65|      51.84|\n",
      "|     K|20100813|  51.02|      51.84|\n",
      "|     K|20100816|  50.94|      51.84|\n",
      "|     K|20100817|  51.57|      51.84|\n",
      "|     K|20100819|  50.91|      51.84|\n",
      "|     K|20100820|  49.86|      51.84|\n",
      "|   LEN|20100721|  14.84|      14.84|\n",
      "|   LEN|20100722|   15.1|      14.84|\n",
      "|   LEN|20100723|  15.06|      14.84|\n",
      "|   LEN|20100726|  15.56|      14.84|\n",
      "|   LEN|20100727|  15.75|      14.84|\n",
      "|   LEN|20100728|  15.06|      14.84|\n",
      "+------+--------+-------+-----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_value = spark.sql(\"select  Ticker,Date,High,\\\n",
    "                       first_value(High) over (partition by Ticker order by Date  ) as first_value \\\n",
    "                       from stock_data \")\n",
    "first_value.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+----------+\n",
      "|Ticker|    Date|   High|last_value|\n",
      "+------+--------+-------+----------+\n",
      "|   GIS|20100721|  35.56|     35.56|\n",
      "|   GIS|20100722|  35.48|     35.48|\n",
      "|   GIS|20100723|  35.58|     35.58|\n",
      "|   GIS|20100726|35.6852|   35.6852|\n",
      "|   GIS|20100727|     36|        36|\n",
      "|   GIS|20100728|  35.91|     35.91|\n",
      "|   GIS|20100729|  35.11|     35.11|\n",
      "|   GIS|20100730|  34.48|     34.48|\n",
      "|   GIS|20100802|  35.03|     35.03|\n",
      "|   GIS|20100803|  34.42|     34.42|\n",
      "+------+--------+-------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "last_value = spark.sql(\"select  Ticker,Date,High,\\\n",
    "                       last_value(High) over (partition by Ticker order by Date  ) as last_value \\\n",
    "                       from stock_data \")\n",
    "last_value.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above results last value of the high is unpredicted hence we need last value to remain same: To get desired results we need to add ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+----------+\n",
      "|Ticker|    Date|   High|last_value|\n",
      "+------+--------+-------+----------+\n",
      "|   GIS|20100721|  35.56|      35.2|\n",
      "|   GIS|20100722|  35.48|      35.2|\n",
      "|   GIS|20100723|  35.58|      35.2|\n",
      "|   GIS|20100726|35.6852|      35.2|\n",
      "|   GIS|20100727|     36|      35.2|\n",
      "|   GIS|20100728|  35.91|      35.2|\n",
      "|   GIS|20100729|  35.11|      35.2|\n",
      "|   GIS|20100730|  34.48|      35.2|\n",
      "|   GIS|20100802|  35.03|      35.2|\n",
      "|   GIS|20100803|  34.42|      35.2|\n",
      "|   GIS|20100804|   34.7|      35.2|\n",
      "|   GIS|20100805|  34.52|      35.2|\n",
      "|   GIS|20100806|  33.73|      35.2|\n",
      "|   GIS|20100809|  33.87|      35.2|\n",
      "|   GIS|20100810|  34.15|      35.2|\n",
      "|   GIS|20100811|  33.98|      35.2|\n",
      "|   GIS|20100812|  34.44|      35.2|\n",
      "|   GIS|20100813|  35.17|      35.2|\n",
      "|   GIS|20100816|  35.16|      35.2|\n",
      "|   GIS|20100817|  35.54|      35.2|\n",
      "|   GIS|20100819|  35.29|      35.2|\n",
      "|   GIS|20100820|   35.2|      35.2|\n",
      "|     K|20100721|  51.84|     49.86|\n",
      "|     K|20100722| 51.625|     49.86|\n",
      "|     K|20100723|   51.4|     49.86|\n",
      "|     K|20100726|  51.51|     49.86|\n",
      "|     K|20100727|  52.58|     49.86|\n",
      "|     K|20100728|  52.48|     49.86|\n",
      "|     K|20100729|   50.1|     49.86|\n",
      "|     K|20100730|  50.16|     49.86|\n",
      "|     K|20100802|  50.53|     49.86|\n",
      "|     K|20100803|  50.07|     49.86|\n",
      "|     K|20100804|  50.95|     49.86|\n",
      "|     K|20100805|   50.6|     49.86|\n",
      "|     K|20100806|  50.24|     49.86|\n",
      "|     K|20100809|  51.09|     49.86|\n",
      "|     K|20100810|  51.84|     49.86|\n",
      "|     K|20100811|  51.38|     49.86|\n",
      "|     K|20100812|  50.65|     49.86|\n",
      "|     K|20100813|  51.02|     49.86|\n",
      "|     K|20100816|  50.94|     49.86|\n",
      "|     K|20100817|  51.57|     49.86|\n",
      "|     K|20100819|  50.91|     49.86|\n",
      "|     K|20100820|  49.86|     49.86|\n",
      "|   LEN|20100721|  14.84|     12.82|\n",
      "|   LEN|20100722|   15.1|     12.82|\n",
      "|   LEN|20100723|  15.06|     12.82|\n",
      "|   LEN|20100726|  15.56|     12.82|\n",
      "|   LEN|20100727|  15.75|     12.82|\n",
      "|   LEN|20100728|  15.06|     12.82|\n",
      "+------+--------+-------+----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "last_value = spark.sql(\"select  Ticker,Date,High,\\\n",
    "last_value(High) over (partition by Ticker order by Date ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)\\\n",
    "                       as last_value \\\n",
    "                       from stock_data \")\n",
    "last_value.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking-Function:\n",
    "\n",
    "Row_number : This function will assign a unique id to each row returned from the query.\n",
    "\n",
    "Rank : This function will assign a unique number to each distinct row, but it leaves a gap between the groups. Let me explain with a query. \n",
    "\n",
    "Dense_rank : \n",
    "This function is similar to Rank with only difference, this will not leave gaps between groups.\n",
    "\n",
    "percent_rank : \n",
    "\n",
    "Calculates the relative rank of a row within a group of rows.\n",
    "\n",
    "ntile: \n",
    "\n",
    "The ntile function takes an integer as an input and divides the records of the result set into that number of groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------+\n",
      "|Ticker|Close|rw_number|\n",
      "+------+-----+---------+\n",
      "|   GIS|33.57|        1|\n",
      "|   GIS| 33.7|        2|\n",
      "|   GIS|33.81|        3|\n",
      "|   GIS|33.85|        4|\n",
      "|   GIS|33.98|        5|\n",
      "|   GIS|33.98|        6|\n",
      "|   GIS|34.13|        7|\n",
      "|   GIS| 34.2|        8|\n",
      "|   GIS|34.35|        9|\n",
      "|   GIS|34.43|       10|\n",
      "|   GIS|34.62|       11|\n",
      "|   GIS|34.86|       12|\n",
      "|   GIS|35.03|       13|\n",
      "|   GIS|35.13|       14|\n",
      "|   GIS|35.14|       15|\n",
      "|   GIS|35.15|       16|\n",
      "|   GIS|35.36|       17|\n",
      "|   GIS|35.38|       18|\n",
      "|   GIS|35.44|       19|\n",
      "|   GIS|35.44|       20|\n",
      "+------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rw_number = spark.sql(\"select Ticker,Close,\\\n",
    "                      row_number() over (partition by Ticker order by Close ) as rw_number from stock_data\")\n",
    "rw_number.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+\n",
      "|Ticker|Close|rnk_number|\n",
      "+------+-----+----------+\n",
      "|   GIS|33.57|         1|\n",
      "|   GIS| 33.7|         2|\n",
      "|   GIS|33.81|         3|\n",
      "|   GIS|33.85|         4|\n",
      "|   GIS|33.98|         5|\n",
      "|   GIS|33.98|         5|\n",
      "|   GIS|34.13|         7|\n",
      "|   GIS| 34.2|         8|\n",
      "|   GIS|34.35|         9|\n",
      "|   GIS|34.43|        10|\n",
      "|   GIS|34.62|        11|\n",
      "|   GIS|34.86|        12|\n",
      "|   GIS|35.03|        13|\n",
      "|   GIS|35.13|        14|\n",
      "|   GIS|35.14|        15|\n",
      "|   GIS|35.15|        16|\n",
      "|   GIS|35.36|        17|\n",
      "|   GIS|35.38|        18|\n",
      "|   GIS|35.44|        19|\n",
      "|   GIS|35.44|        19|\n",
      "+------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnk_number = spark.sql(\"select Ticker,Close,\\\n",
    "                      rank() over (partition by Ticker order by Close ) as rnk_number from stock_data\")\n",
    "rnk_number.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------+\n",
      "|Ticker|Close|dense_number|\n",
      "+------+-----+------------+\n",
      "|   GIS|33.57|           1|\n",
      "|   GIS| 33.7|           2|\n",
      "|   GIS|33.81|           3|\n",
      "|   GIS|33.85|           4|\n",
      "|   GIS|33.98|           5|\n",
      "|   GIS|33.98|           5|\n",
      "|   GIS|34.13|           6|\n",
      "|   GIS| 34.2|           7|\n",
      "|   GIS|34.35|           8|\n",
      "|   GIS|34.43|           9|\n",
      "|   GIS|34.62|          10|\n",
      "|   GIS|34.86|          11|\n",
      "|   GIS|35.03|          12|\n",
      "|   GIS|35.13|          13|\n",
      "|   GIS|35.14|          14|\n",
      "|   GIS|35.15|          15|\n",
      "|   GIS|35.36|          16|\n",
      "|   GIS|35.38|          17|\n",
      "|   GIS|35.44|          18|\n",
      "|   GIS|35.44|          18|\n",
      "+------+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dense_rnk_number = spark.sql(\"select Ticker,Close,\\\n",
    "                      dense_rank() over (partition by Ticker order by Close ) as dense_number from stock_data\")\n",
    "dense_rnk_number.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+\n",
      "|Ticker|Close|     percent_ranking|\n",
      "+------+-----+--------------------+\n",
      "|   GIS|33.57|                 0.0|\n",
      "|   GIS| 33.7|0.047619047619047616|\n",
      "|   GIS|33.81| 0.09523809523809523|\n",
      "|   GIS|33.85| 0.14285714285714285|\n",
      "|   GIS|33.98| 0.19047619047619047|\n",
      "|   GIS|33.98| 0.19047619047619047|\n",
      "|   GIS|34.13|  0.2857142857142857|\n",
      "|   GIS| 34.2|  0.3333333333333333|\n",
      "|   GIS|34.35| 0.38095238095238093|\n",
      "|   GIS|34.43| 0.42857142857142855|\n",
      "|   GIS|34.62| 0.47619047619047616|\n",
      "|   GIS|34.86|  0.5238095238095238|\n",
      "|   GIS|35.03|  0.5714285714285714|\n",
      "|   GIS|35.13|  0.6190476190476191|\n",
      "|   GIS|35.14|  0.6666666666666666|\n",
      "|   GIS|35.15|  0.7142857142857143|\n",
      "|   GIS|35.36|  0.7619047619047619|\n",
      "|   GIS|35.38|  0.8095238095238095|\n",
      "|   GIS|35.44|  0.8571428571428571|\n",
      "|   GIS|35.44|  0.8571428571428571|\n",
      "+------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent_rank = spark.sql(\"select Ticker,Close ,\\\n",
    "                         percent_rank() over (partition by Ticker order by Close) percent_ranking from stock_data\")\n",
    "percent_rank.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+------+\n",
      "|Ticker|    Date|  Close|ntiles|\n",
      "+------+--------+-------+------+\n",
      "|     A|20100722|  28.72|     1|\n",
      "|    AA|20100722|  10.82|     1|\n",
      "|  AAPL|20100722|259.024|     1|\n",
      "|   ABC|20100722|  29.63|     1|\n",
      "|   ABT|20100722|  49.01|     1|\n",
      "|   ACE|20100722|  52.91|     1|\n",
      "|  ADBE|20100722|  28.58|     1|\n",
      "|   ADI|20100722|  30.61|     1|\n",
      "|   ADM|20100722|  27.45|     1|\n",
      "|   ADP|20100722|  41.46|     1|\n",
      "+------+--------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntiles = spark.sql(\"select Ticker,Date,Close ,\\\n",
    "                         ntile() over (partition by Date order by Date) ntiles from stock_data\")\n",
    "ntiles.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
